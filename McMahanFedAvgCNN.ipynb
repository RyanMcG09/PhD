{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de8459f",
   "metadata": {},
   "source": [
    "# Best Version of Federated Learning across Nodes Training a CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c67ed4",
   "metadata": {},
   "source": [
    "New script to run a CNN-based federated system, where we can vary the inner and outer learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba29519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import random\n",
    "import csv\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79732d",
   "metadata": {},
   "source": [
    "Functions to deal with splitting of data or creating models. Basically non-interesting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46fdb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splittingData(x_train,y_train,x_test,y_test,noClients):\n",
    "    trainLen = len(x_train)\n",
    "    clientSize = trainLen/noClients\n",
    "    \n",
    "    x_train_clients = []\n",
    "    y_train_clients = []\n",
    "    x_test_clients = []\n",
    "    y_test_clients = []\n",
    "    \n",
    "    x_train_splits = np.array_split(x_train,noClients)\n",
    "    y_train_splits = np.array_split(y_train,noClients)\n",
    "    x_test_splits = np.array_split(x_test,noClients)\n",
    "    y_test_splits = np.array_split(y_test,noClients)\n",
    "    \n",
    "    for i in range(noClients):\n",
    "        x_train_clients.append(x_train_splits[i])\n",
    "        y_train_clients.append(y_train_splits[i])\n",
    "        x_test_clients.append(x_test_splits[i])\n",
    "        y_test_clients.append(y_test_splits[i])\n",
    "    \n",
    "    return x_train_clients, y_train_clients, x_test_clients, y_test_clients\n",
    "\n",
    "def createModel(iLr):\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=iLr)\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10))\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def createZeroWeightCNN(iLr):\n",
    "    layer1 = [np.zeros(shape = (3,3,3,32), dtype = 'float32'), np.zeros(shape = 32, dtype = 'float32')]\n",
    "    layer2 = [np.zeros(shape = (3,3,32,64), dtype = 'float32'), np.zeros(shape = 64, dtype = 'float32')]\n",
    "    layer3 = [np.zeros(shape = (10816,64), dtype = 'float32'), np.zeros(shape = (64), dtype = 'float32')]\n",
    "    layer4 = [np.zeros(shape = (64,10), dtype = 'float32'), np.zeros(shape = (10), dtype = 'float32')]\n",
    "\n",
    "    testModel = models.Sequential()\n",
    "    testModel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    testModel.add(layers.MaxPooling2D((2, 2)))\n",
    "    testModel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    testModel.add(layers.Flatten())\n",
    "    testModel.add(layers.Dense(64, activation='relu'))\n",
    "    testModel.add(layers.Dense(10))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=iLr)\n",
    "    testModel.layers[0].set_weights(layer1)\n",
    "    testModel.layers[2].set_weights(layer2)\n",
    "    testModel.layers[4].set_weights(layer3)\n",
    "    testModel.layers[5].set_weights(layer4)\n",
    "    testModel.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "    return testModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e5bd70",
   "metadata": {},
   "source": [
    "Federated Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d4c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def McMahanFedAvg(models_,fedModel,numClients,l):\n",
    "    #setup an array to hold the weights and a null array to hold the summation of weights in the federated system\n",
    "    layersNums = [0,2,4,5]    \n",
    "    fedModelWeights = []\n",
    "    mmSum = []\n",
    "    for i in layersNums:\n",
    "        fedModelWeights.append(fedModel.layers[i].weights)\n",
    "        mmSum.append(fedModel.layers[i].weights)\n",
    "    \n",
    "    for i in range(len(layersNums)):\n",
    "        for j in range(len(models_[0].layers[layersNums[i]].weights)):\n",
    "            mmSum[i][j] = mmSum[i][j]*0\n",
    "    \n",
    "    #Perform the summation\n",
    "    for n in range(0,numClients):\n",
    "        count = 0\n",
    "        for i in layersNums:\n",
    "            for j in range(len(models_[0].layers[i].weights)):\n",
    "                mmSum[count][j] = models_[n].layers[i].weights[j] - fedModelWeights[count][j]\n",
    "            count += 1\n",
    "    \n",
    "    #find the new global models parameters\n",
    "    count = 0\n",
    "    for i in layersNums:\n",
    "        for j in range(len(models_[0].layers[i].weights)):\n",
    "            mmSum[count][j] = (l/numClients)*mmSum[count][j]\n",
    "            fedModelWeights[count][j] = fedModelWeights[count][j] + mmSum[count][j]\n",
    "        count += 1\n",
    "    \n",
    "    #Update the global model\n",
    "    count = 0\n",
    "    for i in layersNums:\n",
    "        fedModel.layers[i].set_weights(fedModelWeights[count])\n",
    "        count += 1\n",
    "    return fedModel\n",
    "\n",
    "\n",
    "def runIndivModelsFed(numClients, noEpochs, writer, oLr,iLr, v):\n",
    "    #create local and global models\n",
    "    row = []\n",
    "    fedModel = createModel(iLr)\n",
    "    models = []\n",
    "    for i in range(numClients):\n",
    "        model = createModel(iLr)\n",
    "        models.append(model)\n",
    "        \n",
    "    #training the CNN\n",
    "    for ep in range(0,noEpochs):\n",
    "        start = timer()\n",
    "        for i in range(numClients):\n",
    "            models[i] = fedModel\n",
    "            models[i].fit(x_train_clients[i], y_train_clients[i], epochs=1, verbose=v)\n",
    "        fedModel = McMahanFedAvg(models,fedModel,numClients,oLr)\n",
    "        #testing the CNN\n",
    "        testModelsFed(ep,fedModel,numClients,writer,start,numClients,v,0)\n",
    "\n",
    "    return fedModel, models\n",
    "\n",
    "#Testing the model\n",
    "def testModelsFed(ep,model,numClients,writer,start,NC,v,print_):\n",
    "    fedAcc = 0\n",
    "    row = [numClients, ep+1,0,0]\n",
    "    for i in range (NC):\n",
    "        row.append(0)\n",
    "    for i in range(numClients):\n",
    "        #tesing takes place here\n",
    "        loss, acc = model.evaluate(x_test_clients[i],  y_test_clients[i], verbose=v)\n",
    "        fedAcc += acc/numClients\n",
    "        row[4+i] = acc\n",
    "    print(\"Accuracy at epoch {0} is = {1}\".format(ep,fedAcc))\n",
    "    end = timer()\n",
    "    row[2] = fedAcc\n",
    "    row[3] = end-start\n",
    "    #writing to .txt file\n",
    "    if (print_ == 1):\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63561489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a federated system with 1 clients over 10 epochs\n",
      "Accuracy at epoch 0 is = 0.5914999842643738\n"
     ]
    },
   
   ],
   "source": [
    "#Setting Seeds\n",
    "os.environ['PYTHONHASHSEED']=str(2)\n",
    "tf.random.set_seed(2)\n",
    "np.random.seed(2)\n",
    "random.seed(2)\n",
    "#Variables to alter\n",
    "nClients = 1\n",
    "nEpochs = 10\n",
    "outerLr = 0.5\n",
    "innerLr = 0.001\n",
    "verbose = 0\n",
    "print_ = 0\n",
    "#Opening a file to print into\n",
    "f = open('./FCNNResults.csv', 'w', newline = '')\n",
    "header = ['NumClients', 'NumEpochs','FTA','Time']\n",
    "clients = []\n",
    "for i in range(nClients):\n",
    "    header.append(\"LAN{0}\".format(i))\n",
    "    clients.append(i+1)\n",
    "writer = csv.writer(f)\n",
    "if (print_ == 1):\n",
    "    writer.writerow(header)\n",
    "\n",
    "#Split into 'numClients' number of data sections\n",
    "x_train_clients, y_train_clients, x_test_clients, y_test_clients = splittingData(train_images, train_labels, test_images, test_labels, nClients)\n",
    "\n",
    "#Running the model\n",
    "print(\"Running a federated system with {0} clients over {1} epochs\".format(nClients,nEpochs))\n",
    "fedModel, finalLocalModels = runIndivModelsFed(nClients, nEpochs, writer,outerLr,innerLr,verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bb679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
