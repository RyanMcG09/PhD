{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de8459f",
   "metadata": {},
   "source": [
    "# Federated Learning across Nodes Training a CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c67ed4",
   "metadata": {},
   "source": [
    "New script to run a CNN-based federated system, where we can vary the inner and outer learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba29519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import random\n",
    "import csv\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79732d",
   "metadata": {},
   "source": [
    "Functions to deal with splitting of data or creating models. Basically non-interesting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46fdb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splittingData(x_train,y_train,x_test,y_test,noClients):\n",
    "    trainLen = len(x_train)\n",
    "    clientSize = trainLen/noClients\n",
    "    \n",
    "    x_train_clients = []\n",
    "    y_train_clients = []\n",
    "    x_test_clients = []\n",
    "    y_test_clients = []\n",
    "    \n",
    "    x_train_splits = np.array_split(x_train,noClients)\n",
    "    y_train_splits = np.array_split(y_train,noClients)\n",
    "    x_test_splits = np.array_split(x_test,noClients)\n",
    "    y_test_splits = np.array_split(y_test,noClients)\n",
    "    \n",
    "    for i in range(noClients):\n",
    "        x_train_clients.append(x_train_splits[i])\n",
    "        y_train_clients.append(y_train_splits[i])\n",
    "        x_test_clients.append(x_test_splits[i])\n",
    "        y_test_clients.append(y_test_splits[i])\n",
    "    \n",
    "    return x_train_clients, y_train_clients, x_test_clients, y_test_clients\n",
    "\n",
    "def createModel(iLr):\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=iLr)\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10))\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def createZeroWeightCNN(iLr):\n",
    "    layer1 = [np.zeros(shape = (3,3,3,32), dtype = 'float32'), np.zeros(shape = 32, dtype = 'float32')]\n",
    "    layer2 = [np.zeros(shape = (3,3,32,64), dtype = 'float32'), np.zeros(shape = 64, dtype = 'float32')]\n",
    "    layer3 = [np.zeros(shape = (10816,64), dtype = 'float32'), np.zeros(shape = (64), dtype = 'float32')]\n",
    "    layer4 = [np.zeros(shape = (64,10), dtype = 'float32'), np.zeros(shape = (10), dtype = 'float32')]\n",
    "\n",
    "    testModel = models.Sequential()\n",
    "    testModel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    testModel.add(layers.MaxPooling2D((2, 2)))\n",
    "    testModel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    testModel.add(layers.Flatten())\n",
    "    testModel.add(layers.Dense(64, activation='relu'))\n",
    "    testModel.add(layers.Dense(10))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=iLr)\n",
    "    testModel.layers[0].set_weights(layer1)\n",
    "    testModel.layers[2].set_weights(layer2)\n",
    "    testModel.layers[4].set_weights(layer3)\n",
    "    testModel.layers[5].set_weights(layer4)\n",
    "    testModel.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "    return testModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe007690",
   "metadata": {},
   "source": [
    "Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6100c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plottingDataSets(data, datat):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    numClasses = np.arange(1,len(class_names)+1)\n",
    "    for i in range(nClients):\n",
    "    #for i in range(nClients):\n",
    "        ns = np.zeros(len(class_names))\n",
    "        nst = np.zeros(len(class_names))\n",
    "        for j in range(len(data[0])):\n",
    "            ns[data[i][j][0]] += 1\n",
    "        for j in range(len(datat[0])):\n",
    "            nst[datat[i][j][0]] += 1\n",
    "\n",
    "        ax1.bar(numClasses,ns,alpha=0.5,label=\"Training set {0}\".format(i)) \n",
    "        ax2.bar(numClasses,nst,alpha=0.5,label=\"Testing set {0}\".format(i)) \n",
    "\n",
    "    plt.suptitle(\"The Count of Each Class\", fontsize = 'x-large') \n",
    "    ax1.set_title(\"Clients training Dataset\") \n",
    "    ax2.set_title(\"Clients testing Dataset\")\n",
    "    ax1.set(ylabel = \"Count\", xlabel = \"Class\")\n",
    "    ax2.set(ylabel = \"Count\", xlabel = \"Class\")\n",
    "    ax2.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    ax2.yaxis.set_label_coords(-0.1, 0.5)\n",
    "    ax1.set_xticks(numClasses)\n",
    "    ax2.set_xticks(numClasses)\n",
    "    plt.show()\n",
    "    \n",
    "def plottingFreq(data,datat, class_):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    numClients = np.arange(1,nClients+1)\n",
    "    ncls = np.zeros(nClients)\n",
    "    nclst = np.zeros(nClients)\n",
    "    for i in range(nClients):\n",
    "    #for i in range(nClients):\n",
    "        for j in range(len(data[0])):\n",
    "            if (data[i][j][0] == class_):\n",
    "                ncls[i] += 1\n",
    "        for j in range(len(datat[0])):\n",
    "            if (datat[i][j][0] == class_):\n",
    "                nclst[i] += 1\n",
    "\n",
    "    ax1.bar(numClients,ncls,alpha=1,label=\"Training set {0}\".format(i)) \n",
    "    ax2.bar(numClients,nclst,alpha=1,label=\"Testing set {0}\".format(i)) \n",
    "\n",
    "    fig.suptitle(\"The Count of the Class \"+ str(class_) + \" for each Client\", fontsize='x-large')\n",
    "    ax1.set_title(\"Clients training Dataset\") \n",
    "    ax2.set_title(\"Clients testing Dataset\")\n",
    "    ax1.set(ylabel = \"Count\", xlabel = \"Client Number\")\n",
    "    ax2.set(ylabel = \"Count\", xlabel = \"Client Number\")\n",
    "    ax1.set_xticks(numClients)\n",
    "    ax2.set_xticks(numClients)\n",
    "    ax2.yaxis.set_label_coords(-0.1, 0.5)\n",
    "    #ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "def plotting(data,datat):\n",
    "    plt.rcParams['figure.figsize'] = [8,4]\n",
    "    plottingDataSets(y_train_clients,y_test_clients)\n",
    "    c = np.random.choice(clients)\n",
    "    plottingFreq(y_train_clients,y_test_clients, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e5bd70",
   "metadata": {},
   "source": [
    "Federated Functions, where fedAvg now uses a global learning rate by the following equation:\n",
    "$$\n",
    "  G^t = G^{t-1} + \\dfrac{\\eta}{m}\\sum_{i=1}^{m}(P_i^t - G^{t-1}).\n",
    "  \\label{hi}\n",
    "$$\n",
    "Our loss is taken as the difference between our local model and the global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92d4c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def McMahanFedAvg(models_,fedModel,numClients,l):\n",
    "    #setup an array to hold the weights and a null array to hold the summation of weights in the federated system\n",
    "    layersNums = [0,2,4,5]    \n",
    "    fedModelWeights = []\n",
    "    mmSum = []\n",
    "    for i in layersNums:\n",
    "        fedModelWeights.append(fedModel.layers[i].weights)\n",
    "        mmSum.append(fedModel.layers[i].weights)\n",
    "    \n",
    "    for i in range(len(layersNums)):\n",
    "        for j in range(len(models_[0].layers[layersNums[i]].weights)):\n",
    "            mmSum[i][j] = mmSum[i][j]*0\n",
    "    \n",
    "    #Perform the summation\n",
    "    for n in range(0,numClients):\n",
    "        count = 0\n",
    "        for i in layersNums:\n",
    "            for j in range(len(models_[0].layers[i].weights)):\n",
    "                #mmSum contains the summation of the gradients as seen in the equation outlined in the markdown above\n",
    "                mmSum[count][j] = models_[n].layers[i].weights[j] - fedModelWeights[count][j]\n",
    "            count += 1\n",
    "    \n",
    "    #find the new global models parameters\n",
    "    count = 0\n",
    "    for i in layersNums:\n",
    "        for j in range(len(models_[0].layers[i].weights)):\n",
    "            mmSum[count][j] = (l/numClients)*mmSum[count][j]\n",
    "            fedModelWeights[count][j] = fedModelWeights[count][j] + mmSum[count][j]\n",
    "        count += 1\n",
    "    \n",
    "    #Update the global model\n",
    "    count = 0\n",
    "    for i in layersNums:\n",
    "        fedModel.layers[i].set_weights(fedModelWeights[count])\n",
    "        count += 1\n",
    "    return fedModel\n",
    "\n",
    "\n",
    "def runFed(numClients, noEpochs,nUpdates,bSize, writer, oLr,iLr, v):\n",
    "    #create local and global models\n",
    "    row = []\n",
    "    fedModel = createModel(iLr)\n",
    "    models = []\n",
    "    for i in range(numClients):\n",
    "        model = createModel(iLr)\n",
    "        models.append(model)\n",
    "    \n",
    "    batches = np.arange(bSize)    \n",
    "    #training the CNN\n",
    "    for u in range(nUpdates):\n",
    "        start = timer()\n",
    "        clients = np.arange(nClients)\n",
    "        #Send the current model to all clients\n",
    "        for i in range(nClients):\n",
    "            models[i] = fedModel\n",
    "        #For a batch of clients, train the model\n",
    "        for i in range(bSize):\n",
    "            b = np.random.choice(clients)\n",
    "            #Delete the selected client in the batch from being selected again in next iteration\n",
    "            clients = np.setdiff1d(clients,b)\n",
    "            models[b].fit(x_train_clients[b], y_train_clients[b], epochs=noEpochs, verbose=v)\n",
    "        #Performing our aggregation\n",
    "        fedModel = McMahanFedAvg(models,fedModel,numClients,oLr)\n",
    "        #testing the CNN\n",
    "        testModelsFed(u,fedModel,numClients,writer,start,numClients,v,0)\n",
    "\n",
    "    return fedModel, models\n",
    "\n",
    "def runFedPoisoned(numClients, noEpochs,nUpdates,bSize, writer, oLr,iLr, v):\n",
    "    #create local and global models\n",
    "    row = []\n",
    "    fedModel = createModel(iLr)\n",
    "    models = []\n",
    "    for i in range(numClients):\n",
    "        model = createModel(iLr)\n",
    "        models.append(model)\n",
    "    \n",
    "    batches = np.arange(bSize)    \n",
    "    #training the CNN\n",
    "    for u in range(nUpdates):\n",
    "        start = timer()\n",
    "        clients = np.arange(nClients-1)\n",
    "        #Send the current model to all clients\n",
    "        for i in range(nClients):\n",
    "            models[i] = fedModel\n",
    "        #For a batch of clients, train the model\n",
    "        for i in range(bSize):\n",
    "            if (u == nUpdates-2):\n",
    "                print(\"label-Flipped client selected\")\n",
    "                b = clients[-1]\n",
    "            else:                \n",
    "                b = np.random.choice(clients)\n",
    "            #Delete the selected client in the batch from being selected again in next iteration\n",
    "            clients = np.setdiff1d(clients,b)\n",
    "            models[b].fit(x_train_clients[b], y_train_clients[b], epochs=noEpochs, verbose=v)\n",
    "        #Performing our aggregation\n",
    "        fedModel = McMahanFedAvg(models,fedModel,numClients,oLr)\n",
    "        #testing the CNN\n",
    "        testModelsFed(u,fedModel,numClients,writer,start,numClients,v,0)\n",
    "\n",
    "    return fedModel, models\n",
    "#Testing the model\n",
    "def testModelsFed(u,model,numClients,writer,start,NC,v,print_):\n",
    "    fedAcc = 0\n",
    "    row = [numClients, u+1,0,0]\n",
    "    for i in range (NC):\n",
    "        row.append(0)\n",
    "    for i in range(numClients):\n",
    "        #tesing takes place here\n",
    "        loss, acc = model.evaluate(x_test_clients[i],  y_test_clients[i], verbose=v)\n",
    "        fedAcc += acc/numClients\n",
    "        row[4+i] = acc\n",
    "    print(\"Accuracy at update {0} is = {1}\".format(u,fedAcc))\n",
    "    end = timer()\n",
    "    row[2] = fedAcc\n",
    "    row[3] = end-start\n",
    "    #writing to .txt file\n",
    "    if (print_ == 1):\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0de76",
   "metadata": {},
   "source": [
    "Now lets build a model that takes into account everything we know so far, the learning rate(s), batch size, the number of clients, the number of epochs per training round and the number of training rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63561489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Seeds\n",
    "os.environ['PYTHONHASHSEED']=str(2)\n",
    "tf.random.set_seed(2)\n",
    "np.random.seed(2)\n",
    "random.seed(2)\n",
    "#Variables to alter\n",
    "nClients = 10\n",
    "nUpdates = 5\n",
    "E = 10\n",
    "outerLr = 0.01\n",
    "innerLr = 0.001\n",
    "C = 0.5\n",
    "B = int(np.round(nClients*C))\n",
    "#My own variables to print or to control verbose\n",
    "verbose = 0\n",
    "print_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c1de0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a file to print into\n",
    "f = open('./FCNNResults.csv', 'w', newline = '')\n",
    "header = ['NumClients', 'NumUpdates','FTA','Time']\n",
    "clients = []\n",
    "for i in range(nClients):\n",
    "    header.append(\"LAN{0}\".format(i))\n",
    "    clients.append(i+1)\n",
    "writer = csv.writer(f)\n",
    "if (print_ == 1):\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb47942",
   "metadata": {},
   "source": [
    "Lets play around with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3700590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonIID(x_train,y_train,x_test,y_test,noClients):\n",
    "    trainLen = len(x_train)\n",
    "    clientSize = trainLen/noClients\n",
    "    nClasses = np.arange(len(class_names))\n",
    "    \n",
    "    x_train_clients = []\n",
    "    y_train_clients = []\n",
    "    x_test_clients = []\n",
    "    y_test_clients = []\n",
    "    x_train_new = []\n",
    "    y_train_new = []\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(train_images)):\n",
    "            if (y_train[j] == i):\n",
    "                x_train_new.append(x_train[j])\n",
    "                y_train_new.append(y_train[j])\n",
    "                \n",
    "    x_train_splits = np.array_split(x_train_new,noClients)\n",
    "    y_train_splits = np.array_split(y_train_new,noClients)\n",
    "    x_test_splits = np.array_split(x_test,noClients)\n",
    "    y_test_splits = np.array_split(y_test,noClients)\n",
    "    \n",
    "    for i in range(noClients):\n",
    "        x_train_clients.append(x_train_splits[i])\n",
    "        y_train_clients.append(y_train_splits[i])\n",
    "        x_test_clients.append(x_test_splits[i])\n",
    "        y_test_clients.append(y_test_splits[i])\n",
    "    \n",
    "    return x_train_clients, y_train_clients, x_test_clients, y_test_clients\n",
    "\n",
    "def poisoningSplit(x_train,y_train,x_test,y_test,noClients):\n",
    "    trainLen = len(x_train)\n",
    "    clientSize = trainLen/noClients\n",
    "    \n",
    "    x_train_clients = []\n",
    "    y_train_clients = []\n",
    "    x_test_clients = []\n",
    "    y_test_clients = []\n",
    "    \n",
    "    x_train_splits = np.array_split(x_train,noClients)\n",
    "    y_train_splits = np.array_split(y_train,noClients)\n",
    "    x_test_splits = np.array_split(x_test,noClients)\n",
    "    y_test_splits = np.array_split(y_test,noClients)\n",
    "    \n",
    "    for i in range(noClients):\n",
    "        x_train_clients.append(x_train_splits[i])\n",
    "        y_train_clients.append(y_train_splits[i])\n",
    "        x_test_clients.append(x_test_splits[i])\n",
    "        y_test_clients.append(y_test_splits[i])\n",
    "    classes = [0,9]\n",
    "    for i in range(len(y_train_clients[-1])):\n",
    "        if (y_train_clients[-1][i] == classes[0]):\n",
    "            y_train_clients[-1][i] = classes[1]\n",
    "        elif (y_train_clients[-1][i] == classes[1]):\n",
    "            y_train_clients[-1][i] = classes[0]\n",
    "    return x_train_clients, y_train_clients, x_test_clients, y_test_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d18598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a federated system with 10 clients, using 10 epochs per update, over 5 updates with a batch size of 5\n",
      "Accuracy at update 0 is = 0.5908000051975251\n",
      "Accuracy at update 1 is = 0.6004999935626983\n",
      "Accuracy at update 2 is = 0.6069000005722046\n",
      "Accuracy at update 3 is = 0.6118000090122222\n",
      "Accuracy at update 4 is = 0.6051999926567078\n"
     ]
    }
   ],
   "source": [
    "x_train_clients, y_train_clients, x_test_clients, y_test_clients = splittingData(train_images, train_labels, test_images, test_labels, nClients)\n",
    "print(\"Running a federated system with {0} clients, using {1} epochs per update, over {2} updates with a batch size of {3}\".format(nClients,E, nUpdates,B))\n",
    "fedModel, finalLocalModels = runFed(nClients, E, nUpdates,B, writer,outerLr,innerLr,verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8821e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a federated system with 10 clients, using 10 epochs per update, over 5 updates with a batch size of 5\n",
      "Accuracy at update 0 is = 0.5928999960422515\n",
      "Accuracy at update 1 is = 0.5961000025272369\n",
      "Accuracy at update 2 is = 0.6080999970436096\n",
      "label-Flipped client selected\n",
      "label-Flipped client selected\n",
      "label-Flipped client selected\n",
      "label-Flipped client selected\n",
      "label-Flipped client selected\n",
      "Accuracy at update 3 is = 0.6074000060558319\n",
      "Accuracy at update 4 is = 0.6026000022888183\n"
     ]
    }
   ],
   "source": [
    "x_train_clients, y_train_clients, x_test_clients, y_test_clients = poisoningSplit(train_images, train_labels, test_images, test_labels, nClients)\n",
    "print(\"Running a federated system with {0} clients, using {1} epochs per update, over {2} updates with a batch size of {3}\".format(nClients,E, nUpdates,B))\n",
    "fedModel, finalLocalModels = runFedPoisoned(nClients, E, nUpdates,B, writer,outerLr,innerLr,verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "838d3b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a federated system with 100 clients, using 10 epochs per update, over 5 updates with a batch size of 10\n",
      "Accuracy at update 0 is = 0.0999999998137355\n",
      "Accuracy at update 1 is = 0.10000000018626456\n",
      "Accuracy at update 2 is = 0.09999999983236194\n",
      "Accuracy at update 3 is = 0.10000000007450585\n",
      "Accuracy at update 4 is = 0.10000000022351746\n"
     ]
    }
   ],
   "source": [
    "x_train_clients, y_train_clients, x_test_clients, y_test_clients = nonIID(train_images, train_labels, test_images, test_labels, nClients)\n",
    "print(\"Running a federated system with {0} clients, using {1} epochs per update, over {2} updates with a batch size of {3}\".format(nClients,E, nUpdates,B))\n",
    "fedModel, finalLocalModels = runFed(nClients, E, nUpdates,B, writer,outerLr,innerLr,verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490d95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
